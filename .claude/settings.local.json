{
  "permissions": {
    "allow": [
      "Bash(git remote set-url:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nAdd public workflow guide and GitHub Pages setup\n\n- Add WIP disclaimer to README\n- Rename repo URLs to claude-code-my-workflow\n- Create landing page at docs/index.html\n- Copy rendered guide to docs/ for GitHub Pages\n- Link README to live guide at psantanna.com\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git push:*)",
      "Bash(quarto --version:*)",
      "Bash(__NEW_LINE_77bd949e94484a81__ echo -e \"\\\\n2. Title:\")",
      "Bash(__NEW_LINE_77bd949e94484a81__ echo -e \"\\\\n3. No gradients \\(should be clean background\\):\")",
      "Bash(__NEW_LINE_9a2c49d205329636__ echo -e \"\\\\n4. No SVG icons:\")",
      "Bash(__NEW_LINE_d3751393e99aec57__ echo -e \"\\\\n5. No card grids:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n6. WIP notice present:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n7. Read the full guide button:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n8. Overview list present:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n9. Getting started code block:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n10. GitHub source link:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n11. Footer:\")",
      "Bash(__NEW_LINE_7726a439b675366b__ echo -e \"\\\\n12. HTML well-formed \\(closes properly\\):\")",
      "Bash(tr:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nRedesign landing page and workflow guide styling\n\n- Replace over-designed landing page with clean academic layout\n- Add custom Quarto SCSS theme \\(navy/gold tables, callouts, headings\\)\n- Fix inline code styling via include-in-header override\n- Remove title-block-banner, Scott mention, ChatGPT comparison\n- Add WIP banner to guide, update repo URLs to claude-code-my-workflow\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(python3:*)",
      "Bash(git commit:*)",
      "Bash(gh pr create:*)",
      "Bash(git pull:*)",
      "Bash(git reflog expire:*)",
      "Bash(git gc:*)",
      "WebFetch(domain:journals.sagepub.com)",
      "WebFetch(domain:www.cambridge.org)",
      "WebFetch(domain:www.journals.uchicago.edu)",
      "WebFetch(domain:ajps.org)",
      "WebFetch(domain:apsanet.org)",
      "Bash(head:*)",
      "Bash(grep:*)",
      "Bash(done)",
      "Bash(find:*)",
      "Bash(git -C /Users/wali/Documents/GitHub/claude-code-my-workflow checkout -- quality_reports/session_logs/2026-02-07_hooks-and-pedagogy.md)",
      "Bash(do sed -i '' '/^disable-model-invocation: true$/d' \".claude/skills/$skill/SKILL.md\")",
      "Bash(echo:*)",
      "Bash(test:*)",
      "Bash(do test -f \"Manuscripts/example_paper/$file\")",
      "mcp__paper-search-mcp__search_google_scholar",
      "mcp__aigroup-paper__search_papers",
      "WebFetch(domain:v-dem.net)",
      "WebFetch(domain:www.v-dem.net)",
      "Bash('/Users/wali/Documents/GitHub/claude-code-my-workflow/polisci-research-paper/CLAUDE.md' << 'ENDOFFILE'\n# CLAUDE.MD — Political Science Research Paper Workflow\n\n**Project:** [YOUR PROJECT NAME]\n**Institution:** [YOUR INSTITUTION]\n**Working Branch:** main\n\n---\n\n## Quick Reference: Available Skills & Agents\n\n| Command | What It Does |\n|---------|-------------|\n| `/create-paper [topic]` | End-to-end manuscript orchestrator: outline, draft, review, submit |\n| `/paper-outline [topic]` | Manuscript skeleton: folder structure, section outline, word budget |\n| `/draft-section [section]` | Draft a manuscript section with citation verification and voice audit |\n| `/reviewer-2` | Research design devil's advocate: identification, estimator, robustness |\n| `/submission-checklist [paper]` | Pre-submission quality gate: completeness, formatting, anonymization |\n| `/prep-data [task]` | Data processing: download, standardize codes, merge panels, validate |\n| `/review-r [file]` | R code review: quality, reproducibility, correctness |\n| `/validate-bib` | Cross-reference citations vs bibliography file |\n| `/proofread [filename]` | Grammar/typo/overflow review and report |\n| `/commit [message]` | Stage, commit, create PR, and merge to main |\n\n**Agents:** `proofreader`, `methodology-reviewer`, `domain-reviewer`, `r-reviewer`, `polisci-data-engineer`, `verifier`\n\n**Required Installed Skills** \\(external — not included\\):\n\n| Installed Skill | Used By | Purpose |\n|----------------|---------|---------|\n| `scientific-writing` | `/draft-section` | IMRAD structure, flowing prose |\n| `citation-management` | `/draft-section`, `/validate-bib` | Google Scholar/PubMed search, BibTeX |\n| `humanizer` | `/draft-section` | Remove AI writing patterns |\n\n---\n\n## Project Overview\n\nThis is a standalone workflow template for writing political science research papers with Claude Code. It covers the full lifecycle:\n\n1. **Outline** — structure, word budget, hypothesis stubs\n2. **Data processing** — download, clean, merge datasets\n3. **Drafting** — section-by-section with citation verification\n4. **Review** — hostile methodology review, proofreading\n5. **Submission** — 60+ automated checks, anonymization, replication package\n\nCopy this folder to start a new paper project. All skills, agents, and rules are self-contained.\n\n---\n\n## Folder Structure\n\n```\n[your-paper]/\n├── CLAUDE.md                          # This file\n├── .claude/                           # Claude Code configuration\n│   ├── settings.json                  # Project permissions + hooks\n│   ├── rules/                         # Domain-specific rules \\(auto-loaded\\)\n│   ├── skills/                        # Slash commands\n│   └── agents/                        # Specialized agents\n├── Bibliography_base.bib              # Centralized bibliography\n├── Manuscripts/                       # Research papers\n│   └── example_paper/\n│       ├── main.tex                   # Authoritative manuscript source\n│       ├── main_anonymous.tex         # Blinded version for review\n│       ├── appendix.tex               # Online appendix\n│       ├── cover_letter.tex           # Journal cover letter\n│       ├── figures/                   # Paper-specific figures\n│       ├── tables/                    # Generated .tex table fragments\n│       └── submission/                # Final submission package\n├── Replication/                       # Replication packages\n│   ├── code/                          # Numbered scripts \\(00_master, 01_clean, etc.\\)\n│   ├── data/                          # Raw and processed data\n│   └── output/                        # Generated tables, figures\n├── master_supporting_docs/            # Supporting materials\n│   └── supporting_papers/             # Academic papers for literature review\n├── quality_reports/                   # Review agent reports\n│   ├── plans/                         # Saved implementation plans\n│   └── session_logs/                  # Session history\n├── scripts/                           # Utility scripts\n│   └── log-reminder.py               # Session log reminder hook\n└── PROJECT_MEMORY.md                  # Learned corrections\n```\n\n---\n\n## Working Philosophy\n\n### Plan-First Approach\n\nFor any non-trivial task, Claude enters **plan mode first**:\n1. Draft an approach, list files to modify\n2. Save the plan to `quality_reports/plans/`\n3. Wait for your approval\n4. Implement via the orchestrator protocol\n\n### Continuous Learning\n\nTag corrections with `[LEARN:category]` — they are appended to `PROJECT_MEMORY.md` and persist across sessions.\n\n### Quality Gates\n\n| Threshold | When | What It Means |\n|-----------|------|--------------|\n| **80/100** | Commit | Good enough to save progress |\n| **90/100** | PR | High quality, ready for deployment |\n\n---\n\n## Manuscript Workflow\n\n```\n/create-paper \"Your Paper Title\" --journal APSR --design DID\n  |\n  Phase 1: OUTLINE        <- /paper-outline\n  Phase 2: INPUTS         <- you provide papers, R output\n  Phase 3: DRAFT          <- /draft-section \\(per section\\)\n  Phase 4: REVIEW         <- /reviewer-2 + proofreader\n  Phase 5: POLISH         <- anonymization, formatting\n  Phase 6: SUBMISSION     <- /submission-checklist\n```\n\n---\n\n## Data Processing\n\n```\n/prep-data \"merge V-Dem and WDI for country-year panel 1990-2023\"\n```\n\nKey principles:\n- Never merge by country name — use standardized codes \\(COW, ISO-3\\)\n- Diagnostics after every merge\n- Recode before merge \\(Polity special codes, WDI aggregates\\)\n- Document everything in codebook\n\n---\n\n## Session Startup\n\n```\nClaude, please:\n1. Read CLAUDE.MD\n2. Check recent git commits\n3. Read PROJECT_MEMORY.md\n4. Check quality_reports/plans/ for in-progress plans\n5. State what you understand our goals to be\n```\n\n---\n\n## Getting Started\n\n1. Rename the `example_paper/` folder to your paper's short name\n2. Update this CLAUDE.md with your project details\n3. Upload supporting papers to `master_supporting_docs/supporting_papers/`\n4. Run `/paper-outline \"your topic\" --journal [target]` to begin\nENDOFFILE)",
      "Bash(__NEW_LINE_2cab9ce28ae4255f__ echo \"Written successfully\")",
      "Bash('/Users/wali/Documents/GitHub/claude-code-my-workflow/polisci-dataset-coding/CLAUDE.md' << 'ENDOFFILE'\n# CLAUDE.MD — Political Science AI-Coded Dataset Construction\n\n**Project:** [YOUR DATASET NAME]\n**Institution:** [YOUR INSTITUTION]\n**Working Branch:** main\n\n---\n\n## Quick Reference: Available Skills & Agents\n\n| Command | What It Does |\n|---------|-------------|\n| `/create-dataset [concept]` | AI-coded dataset construction with calibration, human validation, and reliability |\n| `/prep-data [task]` | Data processing: download existing datasets, standardize codes, merge panels |\n| `/review-r [file]` | R code review: quality, reproducibility, correctness |\n| `/reviewer-2` | Research design devil's advocate \\(includes Module Y for AI-coded data\\) |\n| `/commit [message]` | Stage, commit, create PR, and merge to main |\n\n**Agents:** `coding-reliability-reviewer`, `methodology-reviewer`, `r-reviewer`, `polisci-data-engineer`, `verifier`\n\n---\n\n## What This Workflow Does\n\nThis is a standalone template for constructing **original cross-national coded datasets** where Claude serves as the coder. It is designed for political science concepts like judicial independence, media freedom, electoral integrity, etc.\n\n**This is NOT expert coding.** It is LLM-assisted measurement with systematic quality controls:\n- Calibration against benchmark datasets\n- Mandatory human validation\n- Hallucination auditing of evidence citations\n- Temporal boundary enforcement\n- Bias detection and disclosure\n\nCopy this folder to start a new dataset project. All skills, agents, and rules are self-contained.\n\n---\n\n## Folder Structure\n\n```\n[your-dataset]/\n├── CLAUDE.md                          # This file\n├── .claude/                           # Claude Code configuration\n│   ├── settings.json                  # Project permissions + hooks\n│   ├── rules/                         # Domain-specific rules \\(auto-loaded\\)\n│   │   ├── dataset-construction-conventions.md  # THE reference document\n│   │   ├── panel-data-conventions.md  # Country codes and merge protocols\n│   │   ├── quality-gates.md           # Scoring rubrics \\(incl. AI-coded datasets\\)\n│   │   ├── robustness-checklists.md   # Module Y for AI-coded data\n│   │   └── ...                        # Other shared rules\n│   ├── skills/                        # Slash commands\n│   │   ├── create-dataset/            # The main workflow\n│   │   ├── prep-data/                 # For merging with existing datasets\n│   │   ├── review-r/                  # R code review\n│   │   ├── reviewer-2/               # Methodology review\n│   │   └── commit/                    # Git workflow\n│   └── agents/                        # Specialized agents\n│       ├── coding-reliability-reviewer.md  # THE review agent for coded data\n│       ├── methodology-reviewer.md\n│       ├── r-reviewer.md\n│       ├── polisci-data-engineer.md\n│       └── verifier.md\n├── Replication/\n│   ├── code/                          # R scripts for analysis\n│   ├── data/\n│   │   ├── raw/                       # Downloaded benchmark datasets\n│   │   ├── processed/                 # Cleaned/merged datasets\n│   │   └── coded/                     # AI-coded output \\(the product\\)\n│   │       ├── codebook.md            # Variable definitions\n│   │       ├── coding_progress.json   # Batch tracking\n│   │       ├── pilot_results.csv      # Pilot codings\n│   │       ├── coded_*.csv            # Per-batch coded data\n│   │       ├── bridge_cases.csv       # Cross-regional calibration\n│   │       ├── hallucination_audit_log.md\n│   │       ├── provenance.md          # Model version, dates, prompt hash\n│   │       └── methodology_transparency.md  # 9-section report\n│   └── output/                        # Analysis output\n├── master_supporting_docs/\n│   ├── supporting_papers/             # Methodology papers\n│   └── codebooks/                     # Existing dataset codebooks \\(V-Dem, Polity\\)\n├── quality_reports/\n│   ├── plans/                         # Saved implementation plans\n│   └── session_logs/                  # Session history\n├── scripts/                           # Utility scripts\n│   └── log-reminder.py               # Session log reminder hook\n└── PROJECT_MEMORY.md                  # Learned corrections\n```\n\n---\n\n## Working Philosophy\n\n### This Is LLM-Assisted Measurement, Not Expert Coding\n\nClaude is a **systematic coder**, not an expert. The workflow manufactures quality controls:\n\n| What Human Teams Get | What This Workflow Does Instead |\n|---------------------|-------------------------------|\n| Multiple independent coders | Calibration + human validation + dual-pass |\n| Coder training and certification | Codebook with anchor examples + calibration gate |\n| Inter-coder reliability | ICC against benchmarks + test-retest |\n| Coder expertise verification | Hallucination audit of evidence citations |\n| Disagreement resolution | Dual-pass recoding of uncertain cells |\n\n### Plan-First Approach\n\nFor any non-trivial task, Claude enters plan mode first. Plans are saved to `quality_reports/plans/`.\n\n### Continuous Learning\n\nTag corrections with `[LEARN:dataset]` — appended to `PROJECT_MEMORY.md`.\n\n---\n\n## The Pipeline\n\n```\n/create-dataset judicial_independence --countries all --years 2000-2023\n\nStep 0: SCOPE      -> Load conventions, force boundary decisions\nStep 1: CODEBOOK   -> Design variables with anchors + references\n                      GATE: User approves\nStep 2: PILOT      -> 50 countries x 5 years\n                      Calibrate \\(ICC >= 0.75\\)\n                      Hallucination audit \\(>= 80% verified\\)\n                      Human validation \\(ICC >= 0.60\\)\n                      GATE: Pass all three\nStep 3: PRODUCTION -> Code by region, write to disk per batch\nStep 4: EXTENDED   -> \\(optional\\) Prompt sensitivity, adversarial, construct validity\nStep 5: DOCS       -> Methodology transparency report\n                      Launch coding-reliability-reviewer\n                      GATE: User reviews\n```\n\n---\n\n## Quality Gates\n\n| Threshold | Gate |\n|-----------|------|\n| Calibration ICC < 0.75 | Auto-fail |\n| No human validation | Auto-fail |\n| Hallucination rate < 70% verified | Auto-fail |\n| Human validation ICC < 0.60 | Major \\(-15\\) |\n\nFull rubric in `.claude/rules/quality-gates.md` under \"AI-Coded Datasets\".\n\n---\n\n## Key Rules \\(from dataset-construction-conventions.md\\)\n\n1. **Confidence is mandatory** for every cell \\(HIGH/MEDIUM/LOW\\)\n2. **Evidence must be dated** — before December 31 of the coding year\n3. **UNABLE_TO_CODE is always available** — better NA than a guess\n4. **No uniform blocks** — justify > 5 consecutive identical scores\n5. **Never use \"expert\"** to describe Claude's coding in any output\n6. **Write to disk after every batch** — never rely on context persistence\n\n---\n\n## Session Startup\n\n```\nClaude, please:\n1. Read CLAUDE.MD\n2. Read dataset-construction-conventions.md\n3. Read PROJECT_MEMORY.md\n4. Check quality_reports/plans/ for in-progress plans\n5. Check Replication/data/coded/ for existing progress\n6. State what you understand our goals to be\n```\n\n---\n\n## Getting Started\n\n1. Update this CLAUDE.md with your project details\n2. Upload relevant codebook PDFs to `master_supporting_docs/codebooks/`\n3. Upload methodology papers to `master_supporting_docs/supporting_papers/`\n4. Run `/create-dataset \"your concept\" --countries [scope] --years [range]`\n5. Be ready to provide human validation for ~30-50 cases during pilot \\(Step 2\\)\nENDOFFILE)",
      "Bash(__NEW_LINE_be04e0acd628acd2__ echo \"Written successfully\")",
      "Bash(xargs:*)",
      "Bash(do [ -d \".claude/skills/$skill\" ])",
      "mcp__paper-search-mcp__search_arxiv",
      "WebFetch(domain:arxiv.org)",
      "WebFetch(domain:link.springer.com)",
      "WebFetch(domain:www.eddieyang.net)",
      "WebFetch(domain:naokiegami.com)",
      "WebFetch(domain:www.anthropic.com)",
      "WebFetch(domain:research.trychroma.com)",
      "WebFetch(domain:www.getmaxim.ai)",
      "WebFetch(domain:blog.jetbrains.com)",
      "WebFetch(domain:gist.github.com)",
      "WebFetch(domain:substratia.io)",
      "WebFetch(domain:www.medrxiv.org)"
    ]
  }
}
